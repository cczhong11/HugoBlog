---
title: "Spark for ETL"
date: "2018-03-27"
description: "This blog will tell you how to perform ETL on Json file using pySpark."
categories:
    - "Spark"
    - "Cloud computing"
    - "Tips"
---

There is not much information about how could we perform complex operation on pySpark. I summary some tips from stackoverflow and my experience. Hope it will be helpful for you.

# How to Read JSON to DataFrame

# How to Select Nested entities from DataFrame

# How to filter Array object with length in Dataframe 

# How to Drop NA

# How to change Dataframe to RDD

# How to perform array concat with ReduceByKey

